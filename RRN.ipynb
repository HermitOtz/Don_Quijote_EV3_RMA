{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MkT-aT2r4Eb",
        "outputId": "a614bb9a-dd96-42af-8f1c-cec8a7910692"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roFmdyijxJtP",
        "outputId": "37375f2d-6e5f-4a39-e41d-bbbcfaebf126"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.11/dist-packages (1.4.0)\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import re\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, LambdaCallback, ModelCheckpoint\n",
        "import os\n",
        "import glob\n",
        "from tensorflow.keras.models import load_model, Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Dropout, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "!pip install unidecode\n",
        "from unidecode import unidecode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "6BXnyfpzrjWg"
      },
      "outputs": [],
      "source": [
        "with open(\"/content/drive/MyDrive/EV3/Don Quijote de la Mancha.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgM_8p0prx2x",
        "outputId": "e7697af6-49e9-4558-e254-50fe746b4138"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Longitud total del texto: 2071198 caracteres\n",
            "\n",
            "Primeros 1000 caracteres:\n",
            "\n",
            "Capítulo primero. Que trata de la condición y ejercicio del famoso hidalgo\n",
            "don Quijote de la Mancha\n",
            "\n",
            "\n",
            "En un lugar de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho\n",
            "tiempo que vivía un hidalgo de los de lanza en astillero, adarga antigua,\n",
            "rocín flaco y galgo corredor. Una olla de algo más vaca que carnero,\n",
            "salpicón las más noches, duelos y quebrantos los sábados, lantejas los\n",
            "viernes, algún palomino de añadidura los domingos, consumían las tres\n",
            "partes de su hacienda. El resto della concluían sayo de velarte, calzas de\n",
            "velludo para las fiestas, con sus pantuflos de lo mesmo, y los días de\n",
            "entresemana se honraba con su vellorí de lo más fino. Tenía en su casa una\n",
            "ama que pasaba de los cuarenta, y una sobrina que no llegaba a los veinte,\n",
            "y un mozo de campo y plaza, que así ensillaba el rocín como tomaba la\n",
            "podadera. Frisaba la edad de nuestro hidalgo con los cincuenta años; era de\n",
            "complexión recia, seco de carnes, enjuto de rostro, gran madrugador y amigo\n",
            "de la caza. Quieren de\n"
          ]
        }
      ],
      "source": [
        "print(f\"Longitud total del texto: {len(text)} caracteres\\n\")\n",
        "print(\"Primeros 1000 caracteres:\\n\")\n",
        "print(text[:1000])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0UK_J76R7wl"
      },
      "source": [
        "##Limpieza y Normalizacion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEcRYMu-zkul"
      },
      "source": [
        "- Convierte todo el texto a minúsculas.\n",
        "- Elimina acentos y caracteres especiales.\n",
        "- Quita símbolos no deseados, dejando solo letras, puntuación básica y espacios.\n",
        "- Reemplaza múltiples espacios por uno solo y elimina espacios al inicio y final.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjJcnZaT4Kwc",
        "outputId": "a19d7ba8-9c78-4974-92c8-8ef75e9f7080"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto limpio:\n",
            "capitulo primero. que trata de la condicion y ejercicio del famoso hidalgo don quijote de la mancha en un lugar de la mancha, de cuyo nombre no quiero acordarme, no ha mucho tiempo que vivia un hidalgo de los de lanza en astillero, adarga antigua, rocin flaco y galgo corredor. una olla de algo mas vaca que carnero, salpicon las mas noches, duelos y quebrantos los sabados, lantejas los viernes, algun palomino de anadidura los domingos, consumian las tres partes de su hacienda. el resto della concluian sayo de velarte, calzas de velludo para las fiestas, con sus pantuflos de lo mesmo, y los dias de entresemana se honraba con su vellori de lo mas fino. tenia en su casa una ama que pasaba de los cuarenta, y una sobrina que no llegaba a los veinte, y un mozo de campo y plaza, que asi ensillaba el rocin como tomaba la podadera. frisaba la edad de nuestro hidalgo con los cincuenta anos; era de complexion recia, seco de carnes, enjuto de rostro, gran madrugador y amigo de la caza. quieren deci\n"
          ]
        }
      ],
      "source": [
        "text = unidecode(text.lower())\n",
        "text = re.sub(r'[^a-z¿¡.,;:!? ]', ' ', text)\n",
        "text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "print(\"Texto limpio:\")\n",
        "print(text[:1000])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIcDd_7FSBIA"
      },
      "source": [
        "# RNN Palabra y Texto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qz1LGsFQSKe0"
      },
      "source": [
        "## Tokenizar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TEgHmvw0DAY"
      },
      "source": [
        "- Crea un tokenizador con un token especial `<OOV>` para palabras fuera del vocabulario.\n",
        "- Ajusta el tokenizador al texto completo para construir el índice de palabras.\n",
        "- Calcula la cantidad total de palabras únicas.\n",
        "- Evita cargar todas las secuencias en memoria desde el inicio, preparándose para procesar por lotes.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts([text])\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Se procesará el texto en lotes para evitar problemas de memoria\n",
        "# No se crea token_list completa en memoria\n",
        "print(\"Total de palabras únicas:\", total_words)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XE2AMPDniVNC",
        "outputId": "4898296b-5fe8-4674-e551-d584678323ce"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de palabras únicas: 22136\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9l_mHpiSdLw"
      },
      "source": [
        "## Secuencias y Padding de entrenamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_jORlOH0f5L"
      },
      "source": [
        "Se define un generador de datos que procesa el texto dividido en oraciones, tokeniza cada una en n-gramas, y genera secuencias de entrada (`X`) y su palabra objetivo (`y`) de forma incremental. Cada secuencia se trunca a una longitud máxima (`MAX_SEQUENCE_LEN = 50`) y se rellena con ceros por la izquierda. La palabra objetivo se convierte a one-hot (`to_categorical`) y los datos se agrupan en lotes (`batch_size`) para optimizar el uso de memoria. Finalmente, se calcula el número total de secuencias posibles y los pasos por época para el entrenamiento del modelo."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_SEQUENCE_LEN = 50\n",
        "sentences = text.split(\".\")\n",
        "\n",
        "def data_generator(sentences, tokenizer, max_sequence_len, total_words, batch_size=32):\n",
        "    while True:\n",
        "        batch_X = []\n",
        "        batch_y = []\n",
        "        for sentence in sentences:\n",
        "            token_list = tokenizer.texts_to_sequences([sentence])[0]\n",
        "            for i in range(1, len(token_list)):\n",
        "                n_gram_sequence = token_list[:i+1]\n",
        "                if len(n_gram_sequence) > max_sequence_len: # Truncar secuencias muy largas\n",
        "                    n_gram_sequence = n_gram_sequence[-max_sequence_len:]\n",
        "\n",
        "                padded_sequence = pad_sequences([n_gram_sequence], maxlen=max_sequence_len, padding='pre')[0]\n",
        "\n",
        "                X_seq = padded_sequence[:-1]\n",
        "                y_word = padded_sequence[-1]\n",
        "\n",
        "                if y_word == 0:\n",
        "                    continue\n",
        "\n",
        "                batch_X.append(X_seq)\n",
        "                batch_y.append(to_categorical(y_word, num_classes=total_words))\n",
        "\n",
        "                if len(batch_X) == batch_size:\n",
        "                    yield np.array(batch_X), np.array(batch_y)\n",
        "                    batch_X = []\n",
        "                    batch_y = []\n",
        "\n",
        "        if len(batch_X) > 0:\n",
        "            yield np.array(batch_X), np.array(batch_y)\n",
        "\n",
        "\n",
        "num_sequences = 0\n",
        "for sentence in sentences:\n",
        "    token_list = tokenizer.texts_to_sequences([sentence])[0]\n",
        "    num_sequences += max(0, len(token_list) - 1)\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "STEPS_PER_EPOCH = num_sequences // BATCH_SIZE\n",
        "\n",
        "print(f\"MAX_SEQUENCE_LEN: {MAX_SEQUENCE_LEN}\")\n",
        "print(f\"BATCH_SIZE: {BATCH_SIZE}\")\n",
        "print(f\"STEPS_PER_EPOCH: {STEPS_PER_EPOCH}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYFs7fpwjT8S",
        "outputId": "32f2bb96-97f1-45fc-89e5-6519ea51f92b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAX_SEQUENCE_LEN: 50\n",
            "BATCH_SIZE: 128\n",
            "STEPS_PER_EPOCH: 2879\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-S1GsbcCTD-R"
      },
      "source": [
        "## Modelo LSTM y entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "LTY_X1wYvPk1",
        "outputId": "36b48f67-d424-4b7f-a5c9-3a1926e42a9a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │     \u001b[38;5;34m1,416,704\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m98,816\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22136\u001b[0m)          │     \u001b[38;5;34m2,855,544\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,416,704</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22136</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,855,544</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,371,064\u001b[0m (16.67 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,371,064</span> (16.67 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,371,064\u001b[0m (16.67 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,371,064</span> (16.67 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "# === Definición del Modelo ===\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=total_words, output_dim=64, input_length=MAX_SEQUENCE_LEN - 1),\n",
        "    LSTM(128),\n",
        "    Dense(total_words, activation='softmax')\n",
        "])\n",
        "\n",
        "# Construcción explícita del modelo\n",
        "model.build(input_shape=(None, MAX_SEQUENCE_LEN - 1))\n",
        "\n",
        "# Compilación\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',  # porque y es one-hot\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Mostrar resumen\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Callbacks y Entrenamiento"
      ],
      "metadata": {
        "id": "jMo9AzyuCyFU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se definen tres callbacks principales: `EarlyStopping`, que detiene el entrenamiento si la pérdida de validación no mejora después de 15 épocas; `ReduceLROnPlateau`, que reduce el `learning rate` si la validación se estanca, con un mínimo de `0.00005`; y `ModelCheckpoint`, que guarda el mejor modelo basado en `val_accuracy`. Además, se implementa una clase personalizada `TextGenerator`, que genera texto cada 5 épocas usando el modelo actual y una semilla (`don quijote de la mancha`) para observar el progreso del aprendizaje. Finalmente, el modelo se entrena usando un `data_generator` que produce secuencias por lotes, con 100 épocas y validación en un subconjunto de los datos.\n"
      ],
      "metadata": {
        "id": "NaTjR7y_DDVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = EarlyStopping(monitor=\"val_loss\", patience=25, restore_best_weights=True) # Aumentado patience\n",
        "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=7, min_lr=0.000005) # Aumentado patience y min_lr\n",
        "filepath = \"best_model.keras\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor=\"val_accuracy\", verbose=1, save_best_only=True, mode=\"max\")\n",
        "\n",
        "# Generación de texto en cada época\n",
        "def generate_text(seed_text, next_words, model, tokenizer, max_sequence_len):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding=\"pre\")[0]\n",
        "\n",
        "        # Asegurarse de que token_list tenga la forma correcta para el modelo\n",
        "        token_list = np.array(token_list).reshape(1, -1)\n",
        "\n",
        "        predicted_probs = model.predict(token_list, verbose=0)[0]\n",
        "        predicted_word_index = np.argmax(predicted_probs)\n",
        "\n",
        "        output_word = \"\"\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted_word_index:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \" + output_word\n",
        "    return seed_text\n",
        "\n",
        "class TextGenerator(LambdaCallback):\n",
        "    def __init__(self, seed_text, next_words, tokenizer, max_sequence_len):\n",
        "        super().__init__()\n",
        "        self.seed_text = seed_text\n",
        "        self.next_words = next_words\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_sequence_len = max_sequence_len\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if epoch % 5 == 0:\n",
        "            generated = generate_text(self.seed_text, self.next_words, self.model, self.tokenizer, self.max_sequence_len)\n",
        "            print(f\"Epoch {epoch+1} - Generado: {generated}\")\n",
        "\n",
        "seed_text = \"don quijote de la mancha\"\n",
        "text_generator_callback = TextGenerator(seed_text, 20, tokenizer, MAX_SEQUENCE_LEN)\n",
        "\n",
        "\n",
        "history = model.fit(data_generator(sentences, tokenizer, MAX_SEQUENCE_LEN, total_words, BATCH_SIZE),\n",
        "                    steps_per_epoch=STEPS_PER_EPOCH,\n",
        "                    epochs=50,\n",
        "                    verbose=1,\n",
        "                    callbacks=[early_stop, reduce_lr, checkpoint, text_generator_callback],\n",
        "                    validation_data=data_generator(sentences, tokenizer, MAX_SEQUENCE_LEN, total_words, BATCH_SIZE),\n",
        "                    validation_steps=STEPS_PER_EPOCH // 5\n",
        "                   )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoXMmd4dLR00",
        "outputId": "9249829d-90d1-47c1-d3c0-f46317304b42"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.0667 - loss: 6.7566\n",
            "Epoch 1: val_accuracy improved from -inf to 0.10247, saving model to best_model.keras\n",
            "Epoch 1 - Generado: don quijote de la mancha y no no no no no no no no no no no no no no no no no no no\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 38ms/step - accuracy: 0.0667 - loss: 6.7565 - val_accuracy: 0.1025 - val_loss: 6.0207 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m2878/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.1100 - loss: 5.8717\n",
            "Epoch 2: val_accuracy improved from 0.10247 to 0.12265, saving model to best_model.keras\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 37ms/step - accuracy: 0.1100 - loss: 5.8717 - val_accuracy: 0.1226 - val_loss: 5.6885 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.1333 - loss: 5.5010\n",
            "Epoch 3: val_accuracy improved from 0.12265 to 0.15417, saving model to best_model.keras\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 50ms/step - accuracy: 0.1333 - loss: 5.5010 - val_accuracy: 0.1542 - val_loss: 5.3800 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.1518 - loss: 5.2019\n",
            "Epoch 4: val_accuracy improved from 0.15417 to 0.17219, saving model to best_model.keras\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 49ms/step - accuracy: 0.1518 - loss: 5.2019 - val_accuracy: 0.1722 - val_loss: 5.0431 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1633 - loss: 4.9655\n",
            "Epoch 5: val_accuracy improved from 0.17219 to 0.18655, saving model to best_model.keras\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 49ms/step - accuracy: 0.1633 - loss: 4.9654 - val_accuracy: 0.1865 - val_loss: 4.6099 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m2878/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1721 - loss: 4.7690\n",
            "Epoch 6: val_accuracy did not improve from 0.18655\n",
            "Epoch 6 - Generado: don quijote de la mancha y el otro que se le habia dado en la mano y el otro que se le habia dado en\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 37ms/step - accuracy: 0.1721 - loss: 4.7689 - val_accuracy: 0.1732 - val_loss: 4.8943 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m2878/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.1801 - loss: 4.5814\n",
            "Epoch 7: val_accuracy did not improve from 0.18655\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 47ms/step - accuracy: 0.1801 - loss: 4.5814 - val_accuracy: 0.1686 - val_loss: 4.8765 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.1883 - loss: 4.4229\n",
            "Epoch 8: val_accuracy improved from 0.18655 to 0.18859, saving model to best_model.keras\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 49ms/step - accuracy: 0.1883 - loss: 4.4229 - val_accuracy: 0.1886 - val_loss: 4.6046 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m2878/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1975 - loss: 4.2821\n",
            "Epoch 9: val_accuracy improved from 0.18859 to 0.20402, saving model to best_model.keras\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 50ms/step - accuracy: 0.1975 - loss: 4.2821 - val_accuracy: 0.2040 - val_loss: 4.3494 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2092 - loss: 4.1526\n",
            "Epoch 10: val_accuracy improved from 0.20402 to 0.22993, saving model to best_model.keras\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 49ms/step - accuracy: 0.2092 - loss: 4.1526 - val_accuracy: 0.2299 - val_loss: 3.9752 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2229 - loss: 4.0297\n",
            "Epoch 11: val_accuracy did not improve from 0.22993\n",
            "Epoch 11 - Generado: don quijote de la mancha y que le habia dado en el suelo y a don quijote y sancho y el otro dia se le\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 36ms/step - accuracy: 0.2229 - loss: 4.0297 - val_accuracy: 0.1973 - val_loss: 4.3963 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2376 - loss: 3.9157\n",
            "Epoch 12: val_accuracy did not improve from 0.22993\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 48ms/step - accuracy: 0.2376 - loss: 3.9157 - val_accuracy: 0.1888 - val_loss: 4.5399 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m2878/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2517 - loss: 3.8125\n",
            "Epoch 13: val_accuracy did not improve from 0.22993\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 36ms/step - accuracy: 0.2517 - loss: 3.8125 - val_accuracy: 0.2092 - val_loss: 4.2734 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m2878/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2646 - loss: 3.7195\n",
            "Epoch 14: val_accuracy improved from 0.22993 to 0.23099, saving model to best_model.keras\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 49ms/step - accuracy: 0.2646 - loss: 3.7195 - val_accuracy: 0.2310 - val_loss: 4.0353 - learning_rate: 0.0010\n",
            "Epoch 15/50\n",
            "\u001b[1m2878/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2742 - loss: 3.6559\n",
            "Epoch 15: val_accuracy improved from 0.23099 to 0.27508, saving model to best_model.keras\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 49ms/step - accuracy: 0.2742 - loss: 3.6559 - val_accuracy: 0.2751 - val_loss: 3.6366 - learning_rate: 0.0010\n",
            "Epoch 16/50\n",
            "\u001b[1m2878/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2884 - loss: 3.5628\n",
            "Epoch 16: val_accuracy did not improve from 0.27508\n",
            "Epoch 16 - Generado: don quijote de la mancha que no habia de hacer en el mundo que le habia sucedido que no le habia de llevar el de\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 49ms/step - accuracy: 0.2884 - loss: 3.5628 - val_accuracy: 0.2251 - val_loss: 4.0656 - learning_rate: 0.0010\n",
            "Epoch 17/50\n",
            "\u001b[1m2877/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2990 - loss: 3.4841\n",
            "Epoch 17: val_accuracy did not improve from 0.27508\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 36ms/step - accuracy: 0.2991 - loss: 3.4841 - val_accuracy: 0.2040 - val_loss: 4.3202 - learning_rate: 0.0010\n",
            "Epoch 18/50\n",
            "\u001b[1m2878/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.3098 - loss: 3.4159\n",
            "Epoch 18: val_accuracy did not improve from 0.27508\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 49ms/step - accuracy: 0.3098 - loss: 3.4159 - val_accuracy: 0.2316 - val_loss: 4.0411 - learning_rate: 0.0010\n",
            "Epoch 19/50\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.3191 - loss: 3.3495\n",
            "Epoch 19: val_accuracy did not improve from 0.27508\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 49ms/step - accuracy: 0.3191 - loss: 3.3495 - val_accuracy: 0.2508 - val_loss: 3.8673 - learning_rate: 0.0010\n",
            "Epoch 20/50\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.3267 - loss: 3.3032\n",
            "Epoch 20: val_accuracy improved from 0.27508 to 0.30057, saving model to best_model.keras\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 49ms/step - accuracy: 0.3267 - loss: 3.3031 - val_accuracy: 0.3006 - val_loss: 3.4451 - learning_rate: 0.0010\n",
            "Epoch 21/50\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.3351 - loss: 3.2492\n",
            "Epoch 21: val_accuracy did not improve from 0.30057\n",
            "Epoch 21 - Generado: don quijote de la mancha que no habia de hacer en el ansia y el barbero que no habia de hacer en el mundo que\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 51ms/step - accuracy: 0.3351 - loss: 3.2492 - val_accuracy: 0.2490 - val_loss: 3.8526 - learning_rate: 0.0010\n",
            "Epoch 22/50\n",
            "\u001b[1m2878/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.3440 - loss: 3.1885\n",
            "Epoch 22: val_accuracy did not improve from 0.30057\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 48ms/step - accuracy: 0.3440 - loss: 3.1885 - val_accuracy: 0.2160 - val_loss: 4.2038 - learning_rate: 0.0010\n",
            "Epoch 23/50\n",
            "\u001b[1m2878/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.3516 - loss: 3.1409\n",
            "Epoch 23: val_accuracy did not improve from 0.30057\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 49ms/step - accuracy: 0.3516 - loss: 3.1408 - val_accuracy: 0.2448 - val_loss: 3.9203 - learning_rate: 0.0010\n",
            "Epoch 24/50\n",
            "\u001b[1m2878/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.3592 - loss: 3.0965\n",
            "Epoch 24: val_accuracy did not improve from 0.30057\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 36ms/step - accuracy: 0.3592 - loss: 3.0965 - val_accuracy: 0.2622 - val_loss: 3.7716 - learning_rate: 0.0010\n",
            "Epoch 25/50\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.3669 - loss: 3.0500\n",
            "Epoch 25: val_accuracy improved from 0.30057 to 0.32152, saving model to best_model.keras\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 48ms/step - accuracy: 0.3669 - loss: 3.0500 - val_accuracy: 0.3215 - val_loss: 3.3071 - learning_rate: 0.0010\n",
            "Epoch 26/50\n",
            "\u001b[1m2878/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.3726 - loss: 3.0168\n",
            "Epoch 26: val_accuracy did not improve from 0.32152\n",
            "Epoch 26 - Generado: don quijote de la mancha de don quijote que no habia de ver que hacerse pastor de remos en la cabeza y ceptros en las\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 50ms/step - accuracy: 0.3726 - loss: 3.0168 - val_accuracy: 0.2656 - val_loss: 3.7299 - learning_rate: 0.0010\n",
            "Epoch 27/50\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.3804 - loss: 2.9662\n",
            "Epoch 27: val_accuracy did not improve from 0.32152\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 36ms/step - accuracy: 0.3804 - loss: 2.9662 - val_accuracy: 0.2221 - val_loss: 4.1373 - learning_rate: 0.0010\n",
            "Epoch 28/50\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.3865 - loss: 2.9316\n",
            "Epoch 28: val_accuracy did not improve from 0.32152\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 48ms/step - accuracy: 0.3865 - loss: 2.9316 - val_accuracy: 0.2560 - val_loss: 3.8280 - learning_rate: 0.0010\n",
            "Epoch 29/50\n",
            "\u001b[1m2878/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.3916 - loss: 2.8965\n",
            "Epoch 29: val_accuracy did not improve from 0.32152\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 36ms/step - accuracy: 0.3916 - loss: 2.8965 - val_accuracy: 0.2755 - val_loss: 3.6709 - learning_rate: 0.0010\n",
            "Epoch 30/50\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.3984 - loss: 2.8620\n",
            "Epoch 30: val_accuracy improved from 0.32152 to 0.34959, saving model to best_model.keras\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 48ms/step - accuracy: 0.3984 - loss: 2.8620 - val_accuracy: 0.3496 - val_loss: 3.1295 - learning_rate: 0.0010\n",
            "Epoch 31/50\n",
            "\u001b[1m2878/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.4024 - loss: 2.8334\n",
            "Epoch 31: val_accuracy did not improve from 0.34959\n",
            "Epoch 31 - Generado: don quijote de la mancha de don quijote que le molieron no se ejecutan podria dar en su desencanto de dulcinea del toboso pero avinole\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 37ms/step - accuracy: 0.4024 - loss: 2.8334 - val_accuracy: 0.2705 - val_loss: 3.6973 - learning_rate: 0.0010\n",
            "Epoch 32/50\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.4072 - loss: 2.8050\n",
            "Epoch 32: val_accuracy did not improve from 0.34959\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 47ms/step - accuracy: 0.4072 - loss: 2.8050 - val_accuracy: 0.2278 - val_loss: 4.1143 - learning_rate: 0.0010\n",
            "Epoch 33/50\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.4128 - loss: 2.7715\n",
            "Epoch 33: val_accuracy did not improve from 0.34959\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 50ms/step - accuracy: 0.4128 - loss: 2.7715 - val_accuracy: 0.2648 - val_loss: 3.7785 - learning_rate: 0.0010\n",
            "Epoch 34/50\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.4167 - loss: 2.7501\n",
            "Epoch 34: val_accuracy did not improve from 0.34959\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 50ms/step - accuracy: 0.4167 - loss: 2.7500 - val_accuracy: 0.2861 - val_loss: 3.5819 - learning_rate: 0.0010\n",
            "Epoch 35/50\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.4186 - loss: 2.7378\n",
            "Epoch 35: val_accuracy improved from 0.34959 to 0.36260, saving model to best_model.keras\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 38ms/step - accuracy: 0.4186 - loss: 2.7378 - val_accuracy: 0.3626 - val_loss: 3.0478 - learning_rate: 0.0010\n",
            "Epoch 36/50\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.4232 - loss: 2.7134\n",
            "Epoch 36: val_accuracy did not improve from 0.36260\n",
            "Epoch 36 - Generado: don quijote de la mancha dijo sancho que no le hallase ni de las ceremonias o amigas que decir que no podian escaparse de las\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 48ms/step - accuracy: 0.4232 - loss: 2.7134 - val_accuracy: 0.2828 - val_loss: 3.6155 - learning_rate: 0.0010\n",
            "Epoch 37/50\n",
            "\u001b[1m2878/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.4291 - loss: 2.6795\n",
            "Epoch 37: val_accuracy did not improve from 0.36260\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 50ms/step - accuracy: 0.4291 - loss: 2.6795 - val_accuracy: 0.2328 - val_loss: 4.0747 - learning_rate: 0.0010\n",
            "Epoch 38/50\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.4336 - loss: 2.6507\n",
            "Epoch 38: val_accuracy did not improve from 0.36260\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 39ms/step - accuracy: 0.4336 - loss: 2.6507 - val_accuracy: 0.2743 - val_loss: 3.7068 - learning_rate: 0.0010\n",
            "Epoch 39/50\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.4344 - loss: 2.6463\n",
            "Epoch 39: val_accuracy did not improve from 0.36260\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 47ms/step - accuracy: 0.4344 - loss: 2.6463 - val_accuracy: 0.2986 - val_loss: 3.4851 - learning_rate: 0.0010\n",
            "Epoch 40/50\n",
            "\u001b[1m2878/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.4394 - loss: 2.6142\n",
            "Epoch 40: val_accuracy improved from 0.36260 to 0.37420, saving model to best_model.keras\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 38ms/step - accuracy: 0.4394 - loss: 2.6142 - val_accuracy: 0.3742 - val_loss: 2.9694 - learning_rate: 0.0010\n",
            "Epoch 41/50\n",
            "\u001b[1m2878/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.4436 - loss: 2.5947\n",
            "Epoch 41: val_accuracy did not improve from 0.37420\n",
            "Epoch 41 - Generado: don quijote de la mancha dijo sancho que no le habia dado aviso de su senor y preguntole que era lo que tocaba a los\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 38ms/step - accuracy: 0.4436 - loss: 2.5947 - val_accuracy: 0.3034 - val_loss: 3.4631 - learning_rate: 0.0010\n",
            "Epoch 42/50\n",
            "\u001b[1m2878/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.4477 - loss: 2.5710\n",
            "Epoch 42: val_accuracy did not improve from 0.37420\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 39ms/step - accuracy: 0.4477 - loss: 2.5710 - val_accuracy: 0.2373 - val_loss: 4.0180 - learning_rate: 0.0010\n",
            "Epoch 43/50\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.4490 - loss: 2.5619\n",
            "Epoch 43: val_accuracy did not improve from 0.37420\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 48ms/step - accuracy: 0.4490 - loss: 2.5618 - val_accuracy: 0.2765 - val_loss: 3.6897 - learning_rate: 0.0010\n",
            "Epoch 44/50\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.4523 - loss: 2.5391\n",
            "Epoch 44: val_accuracy did not improve from 0.37420\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 38ms/step - accuracy: 0.4524 - loss: 2.5391 - val_accuracy: 0.2879 - val_loss: 3.5972 - learning_rate: 0.0010\n",
            "Epoch 45/50\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.4580 - loss: 2.5188\n",
            "Epoch 45: val_accuracy improved from 0.37420 to 0.38167, saving model to best_model.keras\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 38ms/step - accuracy: 0.4580 - loss: 2.5188 - val_accuracy: 0.3817 - val_loss: 2.9554 - learning_rate: 0.0010\n",
            "Epoch 46/50\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.4585 - loss: 2.5089\n",
            "Epoch 46: val_accuracy did not improve from 0.38167\n",
            "Epoch 46 - Generado: don quijote de la mancha dijo sancho que no le habia dado traidor senor en la memoria la paga que le derribo del agua y\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 48ms/step - accuracy: 0.4585 - loss: 2.5089 - val_accuracy: 0.3115 - val_loss: 3.3969 - learning_rate: 0.0010\n",
            "Epoch 47/50\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.4629 - loss: 2.4859\n",
            "Epoch 47: val_accuracy did not improve from 0.38167\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 37ms/step - accuracy: 0.4629 - loss: 2.4859 - val_accuracy: 0.2393 - val_loss: 4.0310 - learning_rate: 0.0010\n",
            "Epoch 48/50\n",
            "\u001b[1m2878/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.4659 - loss: 2.4668\n",
            "Epoch 48: val_accuracy did not improve from 0.38167\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 48ms/step - accuracy: 0.4659 - loss: 2.4668 - val_accuracy: 0.2768 - val_loss: 3.6992 - learning_rate: 0.0010\n",
            "Epoch 49/50\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.4647 - loss: 2.4695\n",
            "Epoch 49: val_accuracy did not improve from 0.38167\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 49ms/step - accuracy: 0.4647 - loss: 2.4695 - val_accuracy: 0.2890 - val_loss: 3.6248 - learning_rate: 0.0010\n",
            "Epoch 50/50\n",
            "\u001b[1m2878/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.4594 - loss: 2.4904\n",
            "Epoch 50: val_accuracy improved from 0.38167 to 0.38258, saving model to best_model.keras\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 38ms/step - accuracy: 0.4594 - loss: 2.4903 - val_accuracy: 0.3826 - val_loss: 2.9448 - learning_rate: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word(seed_word, model, tokenizer, max_sequence_len):\n",
        "    # Limpiar y tokenizar la palabra de inicio\n",
        "    cleaned_word = unidecode(seed_word.lower())\n",
        "    cleaned_word = re.sub(r'[^a-z¿¡.,;:!? ]', ' ', cleaned_word).strip()\n",
        "\n",
        "    token_list = tokenizer.texts_to_sequences([cleaned_word])[0]\n",
        "\n",
        "    if not token_list:\n",
        "        return \"Palabra no encontrada en el vocabulario.\"\n",
        "\n",
        "\n",
        "    padded_sequence = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')[0]\n",
        "\n",
        "    padded_sequence = np.array(padded_sequence).reshape(1, -1)\n",
        "\n",
        "    predicted_probs = model.predict(padded_sequence, verbose=0)[0]\n",
        "    predicted_word_index = np.argmax(predicted_probs)\n",
        "\n",
        "    output_word = tokenizer.index_word.get(predicted_word_index, \"<OOV>\")\n",
        "\n",
        "    return output_word"
      ],
      "metadata": {
        "id": "LwaspGufrBQ_"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = \"Don\"\n",
        "next_words_to_generate = 1 # Puedes ajustar este número\n",
        "generated_sentence = generate_text(seed_text, next_words_to_generate, model, tokenizer, MAX_SEQUENCE_LEN)\n",
        "print(generated_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAjjnYrNrEa4",
        "outputId": "6c842b7c-4c30-43f1-a370-0cdf89963caa"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Don quijote\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLhteBaUTitP"
      },
      "source": [
        "# RNN Letra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xzg69saVHD6"
      },
      "source": [
        "##Tokenizar por Letra"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se crea un tokenizador a nivel de carácter (`char_level=True`) con un token especial `<OOV>` para caracteres desconocidos. Luego se ajusta al texto completo (`fit_on_texts`) para construir el índice de caracteres. Se calcula el total de caracteres únicos (`char_total`) y se convierte el texto en una secuencia de índices (`char_tokens`). Esto permite entrenar un modelo que predice el siguiente carácter en lugar de la siguiente palabra."
      ],
      "metadata": {
        "id": "pIo_EU52DkCD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "_1UcXSckUEtp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc54b10e-54bd-4b9f-ffac-86c82c9c1212"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de caracteres únicos: 34\n"
          ]
        }
      ],
      "source": [
        "char_tokenizer = Tokenizer(char_level=True, oov_token='<OOV>')\n",
        "char_tokenizer.fit_on_texts([text])\n",
        "\n",
        "char_total = len(char_tokenizer.word_index) + 1\n",
        "char_tokens = char_tokenizer.texts_to_sequences([text])[0]\n",
        "\n",
        "print(\"Total de caracteres únicos:\", char_total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-NlXMtVVKL3"
      },
      "source": [
        "##Generación de sequencia de entrenamientos"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se define una longitud fija de secuencia (`seq_length = 40`) y se recorren los caracteres tokenizados para crear secuencias de entrada y salida. Cada secuencia contiene 40 caracteres como entrada (`X_char`) y el carácter siguiente como etiqueta (`y_char`). Se almacenan todas las secuencias como arrays de NumPy listos para entrenar el modelo. Esta técnica permite al modelo aprender patrones de caracteres para predecir el siguiente carácter en una secuencia dada."
      ],
      "metadata": {
        "id": "C2mtycm2Dx-o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "p06T7EG0UdgY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2630c6e-153c-4b76-84cd-7989f226308a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_char shape: (2056136, 40)\n",
            "y_char shape: (2056136,)\n"
          ]
        }
      ],
      "source": [
        "seq_length = 40\n",
        "\n",
        "input_sequences_char = []\n",
        "\n",
        "for i in range(seq_length, len(char_tokens)):\n",
        "    seq = char_tokens[i - seq_length:i + 1]\n",
        "    input_sequences_char.append(seq)\n",
        "\n",
        "# Convertir a array y separar en X e y\n",
        "input_sequences_char = np.array(input_sequences_char)\n",
        "X_char = input_sequences_char[:, :-1]\n",
        "y_char = input_sequences_char[:, -1]\n",
        "\n",
        "print(\"X_char shape:\", X_char.shape)\n",
        "print(\"y_char shape:\", y_char.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P47GBrsfWc5L"
      },
      "source": [
        "##Callbacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IyHOO0Y4yLJ"
      },
      "source": [
        "###EarlyStop y reduce learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "J6lfgfg1Wvhf"
      },
      "outputs": [],
      "source": [
        "early_stop_char = EarlyStopping(monitor='loss', patience=2, restore_best_weights=True)\n",
        "reduce_lr_char = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJVB23cifzei"
      },
      "source": [
        "###Texto Por epoca"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Genera texto carácter a carácter al final de cada época, usando una semilla fija y muestreo con temperatura para predecir el siguiente carácter. Permite evaluar visualmente el avance del modelo durante el entrenamiento."
      ],
      "metadata": {
        "id": "yqeLUbLDEBWC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "ckQlg0Xdfy9Q"
      },
      "outputs": [],
      "source": [
        "def on_epoch_end_generate_char(epoch, logs):\n",
        "    print(f\"\\n Generación de texto (carácter a carácter) - Época {epoch + 1}\")\n",
        "    seed_text = \"en un lugar de la mancha\"\n",
        "    result = seed_text\n",
        "    for _ in range(300):\n",
        "        token_list = char_tokenizer.texts_to_sequences([result[-40:]])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=40, padding='pre')\n",
        "        preds = model_char.predict(token_list, verbose=0)[0]\n",
        "\n",
        "        preds = np.log(preds + 1e-8) / 0.8\n",
        "        preds = np.exp(preds) / np.sum(np.exp(preds))\n",
        "        next_index = np.random.choice(range(char_total), p=preds)\n",
        "        next_char = char_tokenizer.index_word.get(next_index, '')\n",
        "\n",
        "        result += next_char\n",
        "    print(\"📝 Texto generado:\", result)\n",
        "\n",
        "generate_callback_char = LambdaCallback(on_epoch_end=on_epoch_end_generate_char)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "co2MklhCW0QA"
      },
      "source": [
        "###Gestion de modelos por epoca"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Crea una carpeta específica para almacenar modelos carácter a carácter y define una ruta fija para sobrescribir el modelo después de cada época. El callback `save_callback_char_overwrite` guarda el modelo actual al finalizar cada época, asegurando que siempre exista una versión actualizada disponible.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tIFZXiDUEHmJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "DhEzXKmPWyHi"
      },
      "outputs": [],
      "source": [
        "# Carpeta específica para modelos por carácter\n",
        "model_char_dir = \"/content/drive/MyDrive/EV3/Checkpoints_char\"\n",
        "os.makedirs(model_char_dir, exist_ok=True)\n",
        "\n",
        "previous_char_model_path = {\"path\": None}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "RLu2nRMhXCxR"
      },
      "outputs": [],
      "source": [
        "# Ruta fija para guardar siempre el modelo por letra en el mismo archivo\n",
        "overwrite_char_model_path = os.path.join(model_char_dir, \"modelo_char_actual.keras\")\n",
        "\n",
        "def on_epoch_end_overwrite_char(epoch, logs):\n",
        "    model_char.save(overwrite_char_model_path)\n",
        "    print(f\"💾 Modelo por letra sobrescrito en: {overwrite_char_model_path}\")\n",
        "\n",
        "save_callback_char_overwrite = LambdaCallback(on_epoch_end=on_epoch_end_overwrite_char)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPbohCYSVSIe"
      },
      "source": [
        "##Modelo LSTM y Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "dKP1gn61UtyX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "faf392db-b4af-4ee7-b4c2-5492fc58859f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │         \u001b[38;5;34m2,176\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m98,816\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m)             │         \u001b[38;5;34m4,386\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,176</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,386</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m105,378\u001b[0m (411.63 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">105,378</span> (411.63 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m105,378\u001b[0m (411.63 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">105,378</span> (411.63 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Definir modelo para carácter\n",
        "model_char = Sequential()\n",
        "model_char.add(Embedding(input_dim=char_total, output_dim=64))  # sin input_length\n",
        "model_char.add(LSTM(128))\n",
        "model_char.add(Dense(char_total, activation='softmax'))\n",
        "\n",
        "# Construir con el largo correcto (seq_length = 40)\n",
        "model_char.build(input_shape=(None, seq_length))\n",
        "\n",
        "# Compilar\n",
        "model_char.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Mostrar resumen\n",
        "model_char.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWqsKv7nXV4n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa564d08-ca00-4efa-b9ec-24f484eedfaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m14455/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4234 - loss: 1.8389\n",
            " Generación de texto (carácter a carácter) - Época 1\n",
            "📝 Texto generado: en un lugar de la mancha la alguna alguna agrama se ardado. el entendre consigo don quijote y no has descaido, la de su concos oyendo aqui esta dando o de la honra quien esto, encantares y encigno que le proponido el albordamente, llenas dien tan moligase en mi tiendo temillantes antes. con tan enciempo anostemanza haber d\n",
            "💾 Modelo por letra sobrescrito en: /content/drive/MyDrive/EV3/Checkpoints_char/modelo_char_actual.keras\n",
            "\u001b[1m14458/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 8ms/step - accuracy: 0.4234 - loss: 1.8389 - val_accuracy: 0.5359 - val_loss: 1.4678 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m14451/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5455 - loss: 1.4254\n",
            " Generación de texto (carácter a carácter) - Época 2\n",
            "📝 Texto generado: en un lugar de la mancha que, a surenta con compantado a mucha, sancho panza , y con el, parrona seguro de ellos ocaminas y amigos lo que de los amores los bien tan venia, fue rejero de sus vertidos que en este por las las habian, alli de tanto del infintia ni verdadera, y entiender de los profundariosos y algunas de orrea\n",
            "💾 Modelo por letra sobrescrito en: /content/drive/MyDrive/EV3/Checkpoints_char/modelo_char_actual.keras\n",
            "\u001b[1m14458/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 8ms/step - accuracy: 0.5455 - loss: 1.4254 - val_accuracy: 0.5564 - val_loss: 1.3899 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m14453/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5671 - loss: 1.3509\n",
            " Generación de texto (carácter a carácter) - Época 3\n",
            "📝 Texto generado: en un lugar de la mancha, como se lo menos con del poco y otra rigancia en el mayor despues no dejaban a los pocos de la ferjecio mirar se sepio de ser conselmado de nuestra mas abundos. leja de mi mal fe quiere perdido por todo este amo y decir mas estaba yo me dare bien de estreto que le dejaron de su gusto aquella tierr\n",
            "💾 Modelo por letra sobrescrito en: /content/drive/MyDrive/EV3/Checkpoints_char/modelo_char_actual.keras\n",
            "\u001b[1m14458/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 8ms/step - accuracy: 0.5671 - loss: 1.3509 - val_accuracy: 0.5684 - val_loss: 1.3563 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m14453/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5766 - loss: 1.3166\n",
            " Generación de texto (carácter a carácter) - Época 4\n",
            "📝 Texto generado: en un lugar de la mancha, y mirente; y asi, que no le hace a dellos abardas nos dicen el caredor al estrechando el mano mas partifale y mal acorenta de dios y bien tendido refaltando el cual dijo don quijote; y cual quisiera descubrirla maravillar a los que si ahora se fueron por vuestra merced respondio sancho , porque pe\n",
            "💾 Modelo por letra sobrescrito en: /content/drive/MyDrive/EV3/Checkpoints_char/modelo_char_actual.keras\n",
            "\u001b[1m14458/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 8ms/step - accuracy: 0.5766 - loss: 1.3166 - val_accuracy: 0.5721 - val_loss: 1.3381 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m14458/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5822 - loss: 1.2963\n",
            " Generación de texto (carácter a carácter) - Época 5\n",
            "📝 Texto generado: en un lugar de la mancha . la color en la buena, porque me todos esos ganados con las verdades a una gente creyendo la mancha. !oh acero de los andantes que era noche casa, abrieron a ser tanta noche respondio don quijote de dorote mejor camino a caso . y, ha los ociosos andantes trasaderias, yo la pluncion del torno de la\n",
            "💾 Modelo por letra sobrescrito en: /content/drive/MyDrive/EV3/Checkpoints_char/modelo_char_actual.keras\n",
            "\u001b[1m14458/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 8ms/step - accuracy: 0.5822 - loss: 1.2963 - val_accuracy: 0.5766 - val_loss: 1.3272 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m14457/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5876 - loss: 1.2771\n",
            " Generación de texto (carácter a carácter) - Época 6\n",
            "📝 Texto generado: en un lugar de la mancha, que el cual se ha dicho y honrado la intencion y mi legua, y, pues, creyo, suplicaban un amor la dueno de la insula al enamorado contento de la nombre; y ?que si no los dia que tambien de alto para ser pidenamos, acomdian. si tan respondio sancho . en esto en palabra aventaro de noturlo ahinda, y \n",
            "💾 Modelo por letra sobrescrito en: /content/drive/MyDrive/EV3/Checkpoints_char/modelo_char_actual.keras\n",
            "\u001b[1m14458/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 8ms/step - accuracy: 0.5876 - loss: 1.2771 - val_accuracy: 0.5796 - val_loss: 1.3219 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m14452/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5903 - loss: 1.2665\n",
            " Generación de texto (carácter a carácter) - Época 7\n",
            "📝 Texto generado: en un lugar de la mancha del caballero, y a vuestra merced quieren necullas considores, que me digo yo de gran ojo, su, anti de manana, y asi, puede podia la cabeza. la mancha a velas y visitorios, en lo que se le hallaba amigo le parece con grandisimo dio tento; y soy digna, el don buen senor como si una hora el vino ahor\n",
            "💾 Modelo por letra sobrescrito en: /content/drive/MyDrive/EV3/Checkpoints_char/modelo_char_actual.keras\n",
            "\u001b[1m14458/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 8ms/step - accuracy: 0.5903 - loss: 1.2665 - val_accuracy: 0.5803 - val_loss: 1.3124 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m14457/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5930 - loss: 1.2598\n",
            " Generación de texto (carácter a carácter) - Época 8\n",
            "📝 Texto generado: en un lugar de la mancha, porque si no esta para alguna cosa dos mis sempisimicos que la cual habian dicho, se querian turro respondio don quijote , pero queria no quedara de mucha de mal peligro de su gusto como dijo la duena escudo con la mancha le ha dichos tienes ni mi posible, que en esta puesta del camino de don quij\n",
            "💾 Modelo por letra sobrescrito en: /content/drive/MyDrive/EV3/Checkpoints_char/modelo_char_actual.keras\n",
            "\u001b[1m14458/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 8ms/step - accuracy: 0.5930 - loss: 1.2598 - val_accuracy: 0.5840 - val_loss: 1.3060 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m14456/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5947 - loss: 1.2520\n",
            " Generación de texto (carácter a carácter) - Época 9\n",
            "📝 Texto generado: en un lugar de la manchando de las cazques aquellos contraras, porque esperando que era en el mundo. pero no se que no suele guardasemos don quijote, de la ciudad de volo en el rey de los mas perder caballeros en la platica de todos los que las amadas un buen cerrado en el mundo; es hecho hasta de sus archo, como se vio al\n",
            "💾 Modelo por letra sobrescrito en: /content/drive/MyDrive/EV3/Checkpoints_char/modelo_char_actual.keras\n",
            "\u001b[1m14458/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 8ms/step - accuracy: 0.5947 - loss: 1.2520 - val_accuracy: 0.5849 - val_loss: 1.3015 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m14451/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5962 - loss: 1.2454\n",
            " Generación de texto (carácter a carácter) - Época 10\n",
            "📝 Texto generado: en un lugar de la mancha hecho la mas que os sabe mas la senora dulcinea de su senor, y en el mayor que a la tal que no estaba, con lo que si la misma mas en no hacer la vida, y tanto su comenzo a la festad y a los ojos, le habia habido cuanto el agradecio, y me descubria de espana; y asi, todo la indisculsos y destos de s\n",
            "💾 Modelo por letra sobrescrito en: /content/drive/MyDrive/EV3/Checkpoints_char/modelo_char_actual.keras\n",
            "\u001b[1m14458/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 8ms/step - accuracy: 0.5962 - loss: 1.2454 - val_accuracy: 0.5849 - val_loss: 1.3023 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m14450/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5977 - loss: 1.2425\n",
            " Generación de texto (carácter a carácter) - Época 11\n",
            "📝 Texto generado: en un lugar de la mancha y su tenido malar por la prestance mi cada del mano respondio sancho : si hume a caballo, y que el dio parte del tiempo en la verdad en primera manera: al cuerdo respondio don quijote . donde vi la historia quien en la senora dulcinea del cuerpo se has para la puerta de lo que dio a la venta, que s\n",
            "💾 Modelo por letra sobrescrito en: /content/drive/MyDrive/EV3/Checkpoints_char/modelo_char_actual.keras\n",
            "\u001b[1m14458/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 8ms/step - accuracy: 0.5977 - loss: 1.2425 - val_accuracy: 0.5869 - val_loss: 1.2955 - learning_rate: 0.0010\n",
            "Epoch 12/30\n",
            "\u001b[1m14451/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5993 - loss: 1.2361\n",
            " Generación de texto (carácter a carácter) - Época 12\n",
            "📝 Texto generado: en un lugar de la mancha, y la venta con aquel su senor mismo no perquesos se diciendo: caballero andante que contra la vida. dividia de la senora la desvermada; que yo solo el cual heemoga, y al oficios que las damas, y sin saber a don quijote, no lo entretenio, y que el senor y que, aquel mil alguno dijo sancho , que las\n",
            "💾 Modelo por letra sobrescrito en: /content/drive/MyDrive/EV3/Checkpoints_char/modelo_char_actual.keras\n",
            "\u001b[1m14458/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 8ms/step - accuracy: 0.5993 - loss: 1.2361 - val_accuracy: 0.5870 - val_loss: 1.2943 - learning_rate: 0.0010\n",
            "Epoch 13/30\n",
            "\u001b[1m14456/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5997 - loss: 1.2352\n",
            " Generación de texto (carácter a carácter) - Época 13\n",
            "📝 Texto generado: en un lugar de la mancha que negocio al paje y el tiempo que el tiempo que esto, senor don quijote, que, ahi por venir escribio de alli con ellas. si no han de hacer o dicen que se replico a espejo de su mismo que segura que a nuevo, con todos los retirando, como le tienen cierto de los dos otras manceblas de zoraida, y el\n",
            "💾 Modelo por letra sobrescrito en: /content/drive/MyDrive/EV3/Checkpoints_char/modelo_char_actual.keras\n",
            "\u001b[1m14458/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 8ms/step - accuracy: 0.5997 - loss: 1.2352 - val_accuracy: 0.5867 - val_loss: 1.2935 - learning_rate: 0.0010\n",
            "Epoch 14/30\n",
            "\u001b[1m14449/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6009 - loss: 1.2313\n",
            " Generación de texto (carácter a carácter) - Época 14\n",
            "📝 Texto generado: en un lugar de la mancha. asi que, quiero ser buena manera: pero no se halle el mordo, usa depara en el mundo; y asi, tomaronse el aposento, bien no me prosigue sancho en la cinco y algun hijo del mentir, y mala malmentan y venir los consego, y le habia cada parecer ninguno ver respondio sancho , porque juntame el deseo de\n",
            "💾 Modelo por letra sobrescrito en: /content/drive/MyDrive/EV3/Checkpoints_char/modelo_char_actual.keras\n",
            "\u001b[1m14458/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 8ms/step - accuracy: 0.6009 - loss: 1.2313 - val_accuracy: 0.5880 - val_loss: 1.2920 - learning_rate: 0.0010\n",
            "Epoch 15/30\n",
            "\u001b[1m14458/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6016 - loss: 1.2278\n",
            " Generación de texto (carácter a carácter) - Época 15\n",
            "📝 Texto generado: en un lugar de la mancha, como alecias me lo que los que hace se halla. yo, porque enhas menester que soneto con todo entonce de la campa a mi estarno y gran palabra, sancho dijo don quijote , que vio que vieren nuevas casas el de mi hija, de la cual de peligro hija como en entender y voluntad para alegazo en lo de por enc\n",
            "💾 Modelo por letra sobrescrito en: /content/drive/MyDrive/EV3/Checkpoints_char/modelo_char_actual.keras\n",
            "\u001b[1m14458/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 8ms/step - accuracy: 0.6016 - loss: 1.2278 - val_accuracy: 0.5886 - val_loss: 1.2890 - learning_rate: 0.0010\n",
            "Epoch 16/30\n",
            "\u001b[1m14458/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6021 - loss: 1.2265\n",
            " Generación de texto (carácter a carácter) - Época 16\n",
            "📝 Texto generado: en un lugar de la mancha, senor don fernando del yerro y prometida de la galerase pueda saltando de pobreza solo al rebuzno, dijo: sancho amigo, si aqui fuera mentira de su canticular del que mesmo por medio del mundo que nos hablaban para mucho lo mesmo camino, que don quijote dijo como lo que la invencion castillo la pue\n",
            "💾 Modelo por letra sobrescrito en: /content/drive/MyDrive/EV3/Checkpoints_char/modelo_char_actual.keras\n",
            "\u001b[1m14458/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 8ms/step - accuracy: 0.6021 - loss: 1.2265 - val_accuracy: 0.5895 - val_loss: 1.2885 - learning_rate: 0.0010\n",
            "Epoch 17/30\n",
            "\u001b[1m14455/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6025 - loss: 1.2242\n",
            " Generación de texto (carácter a carácter) - Época 17\n",
            "📝 Texto generado: en un lugar de la mancha de folto con batallas sobre el riezo, por tener castigos y una manera que hizo mi sed de todo salir que estan considerara bien con el memoria. asi como te podia ausente a vuestra merced en su casa por mis pies de colera y bien reposado fue de felice. no tan mundo la doncella que yo aprovechaba, al \n",
            "💾 Modelo por letra sobrescrito en: /content/drive/MyDrive/EV3/Checkpoints_char/modelo_char_actual.keras\n",
            "\u001b[1m14458/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 8ms/step - accuracy: 0.6025 - loss: 1.2242 - val_accuracy: 0.5872 - val_loss: 1.2858 - learning_rate: 0.0010\n",
            "Epoch 18/30\n",
            "\u001b[1m14458/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6042 - loss: 1.2200\n",
            " Generación de texto (carácter a carácter) - Época 18\n",
            "📝 Texto generado: en un lugar de la mancha y su mesma mano de la causa, se me satisfacecido prometido; y en viniere. no me podra las cuales no tengomo y menester llegara, y mas, que lo menos se le impratia o les cristiano de subir de la saludo las saludos, sin que le entendio que tan la mi buen de ser que por es entrado las mias y menos en \n",
            "💾 Modelo por letra sobrescrito en: /content/drive/MyDrive/EV3/Checkpoints_char/modelo_char_actual.keras\n",
            "\u001b[1m14458/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 8ms/step - accuracy: 0.6042 - loss: 1.2200 - val_accuracy: 0.5900 - val_loss: 1.2863 - learning_rate: 0.0010\n",
            "Epoch 19/30\n",
            "\u001b[1m14454/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6045 - loss: 1.2185\n",
            " Generación de texto (carácter a carácter) - Época 19\n",
            "📝 Texto generado: en un lugar de la mancha y gran intencion y sacion que la duquesa de don quijote, de su amoroso sancho respondio sancho , porque los dan pueblos serviros y mucho muy de todo aquello rendir al momento padre que en tocason decian a su grave y con tu displetaban, y de la tuvo a mirar para el, todos sanson menester don quijote\n",
            "💾 Modelo por letra sobrescrito en: /content/drive/MyDrive/EV3/Checkpoints_char/modelo_char_actual.keras\n",
            "\u001b[1m14458/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 8ms/step - accuracy: 0.6045 - loss: 1.2185 - val_accuracy: 0.5883 - val_loss: 1.2881 - learning_rate: 0.0010\n",
            "Epoch 20/30\n",
            "\u001b[1m14455/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6042 - loss: 1.2176\n",
            " Generación de texto (carácter a carácter) - Época 20\n",
            "📝 Texto generado: en un lugar de la mancha, seria respondio sancho , que no tenia, me dio cosa lo que decir, si, porque no lo envio a la duquesa y tanto esperanza ni dejar a la hambre, senores muestras que sustentar que el dia con que se le parecio casadar como cuando me han que yo te sabia decir a una injunto los capitulo. con esto para es\n",
            "💾 Modelo por letra sobrescrito en: /content/drive/MyDrive/EV3/Checkpoints_char/modelo_char_actual.keras\n",
            "\u001b[1m14458/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 8ms/step - accuracy: 0.6042 - loss: 1.2176 - val_accuracy: 0.5913 - val_loss: 1.2837 - learning_rate: 0.0010\n",
            "Epoch 21/30\n",
            "\u001b[1m14457/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6057 - loss: 1.2141\n",
            " Generación de texto (carácter a carácter) - Época 21\n",
            "📝 Texto generado: en un lugar de la mancha, en brinco, en esta alzo por micitos de suceso, y tantos no podra buena duda cabello; y, aunque vio los estribos de dios mas puerto y duda de montesinos; que escudero y promete aquel hombro, que todo el recogiendo la sancho panza a senas, pondre en odilitablo, imposibilidad el viene, con tantas can\n",
            "💾 Modelo por letra sobrescrito en: /content/drive/MyDrive/EV3/Checkpoints_char/modelo_char_actual.keras\n",
            "\u001b[1m14458/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 8ms/step - accuracy: 0.6057 - loss: 1.2141 - val_accuracy: 0.5922 - val_loss: 1.2802 - learning_rate: 0.0010\n",
            "Epoch 22/30\n",
            "\u001b[1m14458/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6060 - loss: 1.2145\n",
            " Generación de texto (carácter a carácter) - Época 22\n",
            "📝 Texto generado: en un lugar de la mancha, como os me viole y de mis cosas de los cosas; y con asi en la color que estopo los tales venta, fuera nombre respondio que el cual se pone el don que, a cada breve aventura sino en una graver el uncimo, como andaban ellas pasados de luscinda. armas se habia de suerte castille. asi aun santia alcal\n",
            "💾 Modelo por letra sobrescrito en: /content/drive/MyDrive/EV3/Checkpoints_char/modelo_char_actual.keras\n",
            "\u001b[1m14458/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 8ms/step - accuracy: 0.6060 - loss: 1.2145 - val_accuracy: 0.5909 - val_loss: 1.2826 - learning_rate: 0.0010\n",
            "Epoch 23/30\n",
            "\u001b[1m14456/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6061 - loss: 1.2128\n",
            " Generación de texto (carácter a carácter) - Época 23\n",
            "📝 Texto generado: en un lugar de la mancha vees vio a su escudero: ahora la silla de mi palabra a cada falias de la batalla, como vuestra merced que tomaron en el que aqui estos pasamos las paz de obrar la hermosa con la carrena de su enamorada, y comenzo la sobresaltado se dale en trabajado de entretenido estaban tienes de caballerias, y d\n",
            "💾 Modelo por letra sobrescrito en: /content/drive/MyDrive/EV3/Checkpoints_char/modelo_char_actual.keras\n",
            "\u001b[1m14458/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 8ms/step - accuracy: 0.6061 - loss: 1.2128 - val_accuracy: 0.5923 - val_loss: 1.2788 - learning_rate: 0.0010\n",
            "Epoch 24/30\n",
            "\u001b[1m14451/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6070 - loss: 1.2114\n",
            " Generación de texto (carácter a carácter) - Época 24\n",
            "📝 Texto generado: en un lugar de la mancha, puesto que alli habia dicho que anselmo determinaria con el emperador casa del toboso; y cuando lo irse del mal que el caballero a lo que prosigue el tendido. esto quedaron mi pecho y traselos le orden que no hay mas de aqui, compadre, sin duda doloricio de pastor de tierra, en una mas doncella se\n",
            "💾 Modelo por letra sobrescrito en: /content/drive/MyDrive/EV3/Checkpoints_char/modelo_char_actual.keras\n",
            "\u001b[1m14458/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 8ms/step - accuracy: 0.6070 - loss: 1.2114 - val_accuracy: 0.5908 - val_loss: 1.2816 - learning_rate: 0.0010\n",
            "Epoch 25/30\n",
            "\u001b[1m14454/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6065 - loss: 1.2118\n",
            " Generación de texto (carácter a carácter) - Época 25\n",
            "📝 Texto generado: en un lugar de la mancha, como hizo mas alguna mano; y si se me ha prendas a la insula pasa, que no se no esperaba, aun estarse los cuerpos mi alforja de mi mujer; egrientes y escribir mas al campo de versos y verde de forzosura; y, siendo mejor presente de su senor con que se dire mulio de buen escudero a campo licencia d\n",
            "💾 Modelo por letra sobrescrito en: /content/drive/MyDrive/EV3/Checkpoints_char/modelo_char_actual.keras\n",
            "\u001b[1m14458/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 8ms/step - accuracy: 0.6065 - loss: 1.2118 - val_accuracy: 0.5923 - val_loss: 1.2776 - learning_rate: 0.0010\n",
            "Epoch 26/30\n",
            "\u001b[1m14458/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6073 - loss: 1.2096\n",
            " Generación de texto (carácter a carácter) - Época 26\n",
            "📝 Texto generado: en un lugar de la mancha ni esto encarta del cura , pues asi, y un buen induha le la recio la segunda y las lenguas andantes de sus llevar de la libro de todo tu lapinado se le diga mejor pasar a la boca , y que te en esto lo que es el bachiller orzaron de mi muerte nosotros pasamos en paraido en el cuerpo en la cala y gal\n",
            "💾 Modelo por letra sobrescrito en: /content/drive/MyDrive/EV3/Checkpoints_char/modelo_char_actual.keras\n",
            "\u001b[1m14458/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 8ms/step - accuracy: 0.6073 - loss: 1.2096 - val_accuracy: 0.5921 - val_loss: 1.2819 - learning_rate: 0.0010\n",
            "Epoch 27/30\n",
            "\u001b[1m14457/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6079 - loss: 1.2078\n",
            " Generación de texto (carácter a carácter) - Época 27\n",
            "📝 Texto generado: en un lugar de la mancha; y es respondio sancho , y el otro un agua para servir que el no os digo que si a mi alli se le ofrece a barbero de la silla, por venir pesar y tan cincularon las deseos de buenas cantadoras que tambien son cuantos tres vida de aquel dia en su mono a su sospo ni anda y hacia. y asi, dijo que habia \n",
            "💾 Modelo por letra sobrescrito en: /content/drive/MyDrive/EV3/Checkpoints_char/modelo_char_actual.keras\n",
            "\u001b[1m14458/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 8ms/step - accuracy: 0.6079 - loss: 1.2078 - val_accuracy: 0.5923 - val_loss: 1.2805 - learning_rate: 0.0010\n",
            "Epoch 28/30\n",
            "\u001b[1m14457/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6081 - loss: 1.2060\n",
            " Generación de texto (carácter a carácter) - Época 28\n",
            "📝 Texto generado: en un lugar de la mancha, hasta que veneros y de las perventas que un grandemo caballero rienda, todos juntos y de sea y del caso que el empleado pudiera en cuanto media vivir la verdad, por sentido a esto en su encuentro que la no hay sancho, las partes de la tres, se acabare como una muerte. pero el comisimo retiro y en \n",
            "💾 Modelo por letra sobrescrito en: /content/drive/MyDrive/EV3/Checkpoints_char/modelo_char_actual.keras\n",
            "\u001b[1m14458/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 8ms/step - accuracy: 0.6081 - loss: 1.2060 - val_accuracy: 0.5926 - val_loss: 1.2773 - learning_rate: 0.0010\n",
            "Epoch 29/30\n",
            "\u001b[1m14456/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6076 - loss: 1.2072\n",
            " Generación de texto (carácter a carácter) - Época 29\n",
            "📝 Texto generado: en un lugar de la mancha. el cura, sino mas libro de su bacia y bien cuenta de la espada la duquesa de la honra, lo cual profesion tras ella estos dos colores y al lecho, que es dicho enganado al delante de la estrana y dimoscon oficio de caballeros andantes de mi senor de cubierto, porque quiero de ser que se hasta recibl\n",
            "💾 Modelo por letra sobrescrito en: /content/drive/MyDrive/EV3/Checkpoints_char/modelo_char_actual.keras\n",
            "\u001b[1m14458/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 8ms/step - accuracy: 0.6076 - loss: 1.2072 - val_accuracy: 0.5923 - val_loss: 1.2777 - learning_rate: 0.0010\n",
            "Epoch 30/30\n",
            "\u001b[1m14456/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6075 - loss: 1.2068\n",
            " Generación de texto (carácter a carácter) - Época 30\n",
            "📝 Texto generado: en un lugar de la mancha cuando compas del contino, el figura el ventero que no lo de una hora la sataria, y aun respondio sancho , pues en fin, y si nos habia mas de tarde de su casa de quitar a la respuesta, y toda saber que en el mundo le habia de contrario de su desnucha del tiempo ignorante a los faltas que veis a la \n",
            "💾 Modelo por letra sobrescrito en: /content/drive/MyDrive/EV3/Checkpoints_char/modelo_char_actual.keras\n",
            "\u001b[1m14458/14458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 8ms/step - accuracy: 0.6075 - loss: 1.2068 - val_accuracy: 0.5932 - val_loss: 1.2769 - learning_rate: 0.0010\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a9aef9d7690>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "model_char.fit( X_char, y_char, epochs=30, batch_size=128, validation_split=0.1,\n",
        "               callbacks=[ early_stop_char, reduce_lr_char, generate_callback_char, save_callback_char_overwrite   ])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carga un modelo previamente entrenado y, dado un texto semilla, predice el siguiente carácter usando muestreo con temperatura. Convierte la semilla en secuencia, la ajusta al tamaño requerido (`seq_length`) y devuelve el carácter más probable según la distribución generada.\n"
      ],
      "metadata": {
        "id": "wAcq8WDPErue"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "3qx1UiOgkN4J"
      },
      "outputs": [],
      "source": [
        "def predict_next_char_from_path(seed_text, path_modelo, tokenizer, seq_length, vocab_size, temperature=1.0):\n",
        "    model = load_model(path_modelo)\n",
        "\n",
        "    seed_text = seed_text.lower()\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text[-seq_length:]])[0]\n",
        "    token_list = pad_sequences([token_list], maxlen=seq_length, padding='pre')\n",
        "\n",
        "    preds = model.predict(token_list, verbose=0)[0]\n",
        "    preds = np.log(preds + 1e-8) / temperature\n",
        "    preds = np.exp(preds) / np.sum(np.exp(preds))\n",
        "\n",
        "    next_index = np.random.choice(range(vocab_size), p=preds)\n",
        "    next_char = tokenizer.index_word.get(next_index, '')\n",
        "    return next_char"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "ABmurq-mkOUF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "41b3852e-06a4-4b2c-ceb1-55aa2bde09bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'o'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "ruta_modelo = \"/content/drive/MyDrive/EV3/Checkpoints_char/modelo_char_actual.keras\"\n",
        "predict_next_char_from_path(\"sanch\", ruta_modelo, char_tokenizer, seq_length=40, vocab_size=char_total)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}